{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "最初に今週必要なPythonパッケージをインストールします。\n",
        "\n",
        "```bash\n",
        "$ git pull\n",
        "$ pipenv install\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext expectmagic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 前処理（続き）\n",
        "\n",
        "## ゴミの除去\n",
        "### 正規表現（続き）\n",
        "\n",
        "### 実習: Wikipediaのダンプの内部リンクをプレーンテキストに変換しよう\n",
        "\n",
        "復習ともう少し複雑な正規表現の処理を兼ねて。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 実習用ファイルのダウンロード\n",
        "from urllib import request\n",
        "\n",
        "with open('data/uk.txt', 'wb') as f, request.urlopen('https://gist.githubusercontent.com/pizzacat83/9a9609d393c251b8df8e5bde96cd38c6/raw/141e1a9344e1cc7a8515e0ab85e57a92733435b7/uk.txt') as req:\n",
        "    f.write(req.read())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### tutor-only\n",
        "\n",
        "import os\n",
        "assert os.path.exists('data/uk.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. ファイル読み込み（復習）\n",
        "`data/uk.txt`を読み込んで，`text`という変数にファイルの内容を代入してください。その後，`text`を表示してください。\n",
        "\n",
        "- ファイルを開く関数`open('ファイルパス', 'モード (optional)')`\n",
        "- 一気にファイル全体を読みこむメソッド`f.read()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### answer\n",
        "\n",
        "f = open('data/uk.txt')\n",
        "text = f.read()\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`[[ほにゃらら]]`という形で内部リンクが表示されています。これを`ほにゃらら`に変換していきます。雑にやるなら`[[`と`]]`を全部削除してしまうわけですが，今回は対応している括弧だけを除去したいという設定でいきます。\n",
        "\n",
        "#### 内部リンクの検出\n",
        "\n",
        "**タスク**: `text`に含まれる`[[...]]`に，括弧ごとマッチするような正規表現`r`を作成してください。その後，その正規表現にマッチする文字列を全て列挙してください。\n",
        "\n",
        "[Python公式チュートリアル](https://docs.python.org/ja/3/howto/regex.html)\n",
        "\n",
        "- まず`re`をインポート\n",
        "- 正規表現は`re.compile('source')`で作る\n",
        "- 「どんな文字でもいい，何文字でもいい」: `.*`\n",
        "  - 最短マッチにするなら`.*?`\n",
        "- パターンを全て検索するには`r.findall('検索対象文字列')`\n",
        "\n",
        "\n",
        "- `[tsg]`: `t`, `s`, `g`のいずれか1文字にマッチ\n",
        "- `.`: 改行以外の任意の1文字にマッチ\n",
        "- `*`: 0回以上の繰り返し\n",
        "- `+`: 1回以上の繰り返し\n",
        "- `?`: `*` `+`の後につけると最左マッチになる（デフォルトは最長マッチ）\n",
        "- `pattern1|pattern2`: `pattern1`または`pattern2`にマッチ\n",
        "- `(pattern)`: グルーピング。演算子の優先度を変えるのにも使えるし，`()`内にマッチしたテキストを得ることもできる\n",
        "- `\\`: 特殊文字のエスケープ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%expect ['[[イングランド]]', '[[スコットランド]]', '[[ウェールズ]]', '[[北アイルランド]]', '[[ロンドン]]', '[[エディンバラ]]', '[[カーディフ]]', '[[ベルファスト]]']\n",
        "### answer\n",
        "\n",
        "import re\n",
        "\n",
        "#r = re.compile('\\\\[\\\\[.+?\\\\]\\\\]')\n",
        "r = re.compile('\\[\\[.+?\\]\\]')\n",
        "\n",
        "r.findall(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**注意点**\n",
        "- `[`と`]`は`[tsg]`で使う特殊文字なので，文字としての`[`を指定したいときは`/`でエスケープ\n",
        "- `'\\['`ではpythonが`\\`をpythonの文字列のエスケープ文字`\\`として認識してしまう\n",
        "  + `\\n`と表示される文字列を作ろうとして`'\\n'`とすると改行になってしまうので，`'\\\\n'`と書くのと同じ\n",
        "  + つまり`'\\\\['`と書けば良い\n",
        "  + 正規表現ではこうしたダブルバックスラッシュを多用するので，代わりに`\\`を文字の`\\`として扱ってくれる文字列リテラル`r'...'`を使うことも"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 括弧の除去\n",
        "前回は`《ルビ》`を丸ごと除去する（空文字列で置換する）という処理をしましたが，今回は丸ごと削除ではなく，括弧の中のテキストは残す必要があります。つまり，`[[ほにゃらら]]`を`ほにゃらら`で置換できれば良さそうです。\n",
        "\n",
        "これを可能にするのが**グルーピング**です。検出した部分のうち括弧の中身だけを残したいので，括弧の中身をグルーピングします。グルーピングをするには，パターンを`()`で括ります。括った上で，まずは`findall`してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%%expect ['イングランド', 'スコットランド', 'ウェールズ', '北アイルランド', 'ロンドン', 'エディンバラ', 'カーディフ', 'ベルファスト']\n",
        "### answer\n",
        "\n",
        "r = re.compile('\\[\\[(.+?)\\]\\]')\n",
        "\n",
        "r.findall(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`[[ほにゃらら]]`を`ほにゃらら`に置換するのにも前回同様`r.sub('置換後', '対象文字列')`を使います。ただし，置換後に指定したいものはかっこの中身であり，マッチごとに異なります。置換後の文字列には先ほど作ったグループを指定することができます。かっこの中身は1番目のグループなので，`\\1`と指定することで括弧の中身に置換することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 例\n",
        "\n",
        "r.sub('\\\\1', 'abc[[def]]g[[h]]i')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### tutor-only\n",
        "\n",
        "assert _ == 'abcdefghi'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**タスク**: `text`の`[[ほにゃらら]]`を`ほにゃらら`に置換してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%expect 'イギリスは四つの非独立国であるイングランド、スコットランド、ウェールズ、北アイルランドより構成される。それぞれの国は首都を持ち、ロンドン（イングランド）、エディンバラ（スコットランド）、カーディフ（ウェールズ）、ベルファスト（北アイルランド）がそれである。中でもイングランドの首都であるロンドンは、イギリスの首都としての機能も置かれる。'\n",
        "### answer\n",
        "\n",
        "r.sub('\\\\1', text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 正規化\n",
        "本質的に区別する必要がない表層的な違いを統一します。\n",
        "\n",
        "- アルファベットを全て小文字に\n",
        "- 半角・全角の統一\n",
        "\n",
        "ex. [たほいやの正規化関数](https://github.com/tsg-ut/slackbot/blob/513fcced5c957f6484f9e306e9b5586691eaa044/tahoiya/lib.js#L117-L129)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# アルファベットの大文字・小文字変換\n",
        "\n",
        "text = 'pizzacat83 lives in Japan.'\n",
        "\n",
        "print(text)\n",
        "print(text.lower()) # 小文字\n",
        "print(text.upper()) # 大文字\n",
        "print(text.capitalize()) # 1文字目だけ大文字\n",
        "print(text.title()) # 単語頭だけ大文字"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 半角・全角の統一\n",
        "\n",
        "import jaconv\n",
        "\n",
        "text = 'ぬるぽｶﾞｯＮｕｌｌPointer１２３４５67890'\n",
        "\n",
        "print(text)\n",
        "print(jaconv.h2z(text)) # Hankaku2Zenkaku デフォルトではカタカナのみ\n",
        "print(jaconv.h2z(text, ascii=True, digit=True)) # 英数字も変換対象に\n",
        "print(jaconv.z2h(text, ascii=True, digit=True)) # 全角→半角\n",
        "print(jaconv.hira2kata(text)) # ひらがな→カタカナ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 形態素解析\n",
        "形態素解析とは，文字列を単語※単位に分割し，各単語の文法的情報を推定する処理です。日本語は単語を区切らないため，形態素解析によって単語の境界を検出する処理はほぼ必須です。単語区切りのみを目的に形態素解析をすることさえあります。\n",
        "\n",
        "ちなみに英語は日本語と異なり単語をスペースで区切りますが，同じ綴りで品詞が異なる単語が多いため，品詞を推定するために形態素解析をすることがあります。\n",
        "\n",
        "※正確には単語単位ではない\n",
        "\n",
        "### インストール\n",
        "\n",
        "まずはおそらく一番メジャーな形態素解析器であるMeCabをインストールしましょう。\n",
        "\n",
        "#### Windows\n",
        "\n",
        "[公式サイト](https://taku910.github.io/mecab/#download)からインストーラを落として実行。\n",
        "\n",
        "#### Mac\n",
        "\n",
        "```bash\n",
        "$ brew install mecab\n",
        "```\n",
        "\n",
        "### 遊んでみよう\n",
        "\n",
        "```bash\n",
        "$ mecab\n",
        "すもももももももものうち\n",
        "すもも  名詞,一般,*,*,*,*,すもも,スモモ,スモモ\n",
        "も      助詞,係助詞,*,*,*,*,も,モ,モ\n",
        "もも    名詞,一般,*,*,*,*,もも,モモ,モモ\n",
        "も      助詞,係助詞,*,*,*,*,も,モ,モ\n",
        "もも    名詞,一般,*,*,*,*,もも,モモ,モモ\n",
        "の      助詞,連体化,*,*,*,*,の,ノ,ノ\n",
        "うち    名詞,非自立,副詞可能,*,*,*,うち,ウチ,ウチ\n",
        "EOS\n",
        "```\n",
        "Ctrl+Cで終了。\n",
        "\n",
        "前処理が単語のスペース区切りで十分な場合も多く，これが手軽にできるオプションが存在します。\n",
        "```\n",
        "$ mecab -Owakati\n",
        "すもももももももものうち\n",
        "すもも も もも も もも の うち \n",
        "```\n",
        "\n",
        "### 色々な形態素解析器\n",
        "日本語の形態素解析器はMeCabだけではありません。\n",
        "\n",
        "- [MeCab](https://taku910.github.io/mecab/) 速い\n",
        "- [JUMAN](http://nlp.ist.i.kyoto-u.ac.jp/index.php?JUMAN) 同じスコアの最適解を出力\n",
        "  + [demo](http://lotus.kuee.kyoto-u.ac.jp/nl-resource/cgi-bin/juman.cgi)\n",
        "- [JUMAN++](http://nlp.ist.i.kyoto-u.ac.jp/index.php?JUMAN++) RNN 文全体を考慮した解析\n",
        "  + [demo](http://tulip.kuee.kyoto-u.ac.jp/demo/jumanpp_lattice)\n",
        "- [KyTea](http://www.phontron.com/kytea/index-ja.html) 点推定\n",
        "  + [demo?](https://twitter.com/KyTeaJa)\n",
        "- [kuromoji](https://www.atilika.com/ja/kuromoji/)\n",
        "\n",
        "前処理に使う形態素解析器を選定する際には，形態素解析器の性能と辞書の性能を混同しないようにしましょう。例えばJUMANのデモの単語のドメインや代表表記に心惹かれたかもしれませんが，それは辞書にその情報が書かれているからであり，JUMANの解析アルゴリズムの性能ではありません。JUMANの辞書をMeCabで使えばMeCabの速度とJUMAN辞書の便利な情報をいいとこ取りできます。\n",
        "\n",
        "### 実習: Pythonで形態素解析\n",
        "\n",
        "形態素解析を使った前処理をPython上でやっていきます。`MeCab`というモジュールを使います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import MeCab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tagger = MeCab.Tagger()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = 'メロスは激怒した。必ず、かの邪智暴虐の王を除かなければならぬと決意した。'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(tagger.parse(text)) # ターミナル上で実行するのと同じ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "各単語について繰り返し処理をする際は，`tagger.parseToNode`を使用します。返り値は連結リストの先頭ノードで，少し慣れが必要かもしれません。\n",
        "\n",
        "#### 0. parseToNodeの用例"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "node = tagger.parseToNode(text)\n",
        "\n",
        "while node.next: # 次のノードがなくなる（終端）まで\n",
        "    node = node.next # 次のノードを見る\n",
        "    \n",
        "    print(node.surface, # 表層形\n",
        "          node.feature) # 形態素の詳細"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. 分かち書き\n",
        "上のコードを参考にして，`text`を形態素解析した結果の**表層形**のリスト`wakati`を作成してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### answer\n",
        "\n",
        "node = tagger.parseToNode(text)\n",
        "wakati = []\n",
        "\n",
        "while node.next:\n",
        "    node = node.next\n",
        "    \n",
        "    wakati.append(node.surface)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%expect ['メロス', 'は', '激怒', 'し', 'た', '。', '必ず', '、', 'かの', '邪智', '暴虐', 'の', '王', 'を', '除か', 'なけれ', 'ば', 'なら', 'ぬ', 'と', '決意', 'し', 'た', '。', '']\n",
        "\n",
        "wakati"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.  原形に正規化\n",
        "`text`を形態素解析した結果の**原形**のリスト`wakati2`を作成してください。\n",
        "\n",
        "`node.feature`には形態素解析結果が記録されています。この場合はカンマ区切りの文字列になっているため，ここから原形を抽出する必要があります。正規表現でも抽出は可能ですが，指定した文字で文字列を区切るだけなら`'string'.split('区切り文字')`というシンプルなメソッドが存在します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 例（というよりヒント）\n",
        "\n",
        "'動詞,自立,*,*,五段・カ行イ音便,未然形,除く,ノゾカ,ノゾカ'.split(',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### answer\n",
        "\n",
        "node = tagger.parseToNode(text)\n",
        "wakati2 = []\n",
        "\n",
        "while node.next:\n",
        "    node = node.next\n",
        "    \n",
        "    wakati2.append(node.feature.split(',')[6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%expect ['*', 'は', '激怒', 'する', 'た', '。', '必ず', '、', 'かの', '邪智', '暴虐', 'の', '王', 'を', '除く', 'ない', 'ば', 'なる', 'ぬ', 'と', '決意', 'する', 'た', '。', '*']\n",
        "\n",
        "wakati2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "欠損値`'*'`を処理できるとなお良い。\n",
        "\n",
        "#### 3. 名詞の抽出\n",
        "textを形態素解析し，名詞のみの表層形からなるリスト`nouns`を作成してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### answer\n",
        "\n",
        "node = tagger.parseToNode(text)\n",
        "nouns = []\n",
        "\n",
        "while node.next:\n",
        "    node = node.next\n",
        "    if node.feature.split(',')[0] == '名詞':\n",
        "        nouns.append(node.surface)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%expect ['メロス', '激怒', '邪智', '暴虐', '王', '決意']\n",
        "\n",
        "nouns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 構文解析\n",
        "文節を単位にした係り受け解析などを行います。前処理として行うことは少ないので，紹介にとどめます。\n",
        "\n",
        "### 主な構文解析器\n",
        "- [CaboCha](https://taku910.github.io/cabocha/)\n",
        "  + MeCab系\n",
        "  + 形態素解析済みの入力も処理できる\n",
        "  + 係り受け解析・固有表現認識\n",
        "  + `brew install cabocha`\n",
        "- [KNP](http://nlp.ist.i.kyoto-u.ac.jp/index.php?KNP)\n",
        "  + JUMAN系\n",
        "  + 係り受け解析・固有表現認識・格・照応解析\n",
        "  + [demo](http://lotus.kuee.kyoto-u.ac.jp/nl-resource/cgi-bin/knp.cgi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 2
}
